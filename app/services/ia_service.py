import os
import requests
import pickle
from dotenv import load_dotenv

load_dotenv()

# Config from .env with defaults
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME", "all-MiniLM-L6-v2")
INDEX_FILE = os.getenv("VECTOR_DB_INDEX", "data/vector_db/index.faiss")
DOC_FILE = os.getenv("VECTOR_DB_DOCS", "data/vector_db/docs.pkl")

# Use external Ollama service or fallback
OLLAMA_API_URL = os.getenv("OLLAMA_API_URL", "http://localhost:11434/api/generate")
OLLAMA_MODEL_NAME = os.getenv("OLLAMA_MODEL_NAME", "mistral")

# Fallback mode when dependencies are not available
FALLBACK_MODE = os.getenv("FALLBACK_MODE", "true").lower() == "true"

# Initialize model with error handling (optional dependency)
MODEL = None
try:
    from sentence_transformers import SentenceTransformer
    print(f"ğŸ”„ Loading embedding model '{EMBEDDING_MODEL_NAME}'...")
    MODEL = SentenceTransformer(EMBEDDING_MODEL_NAME)
    print(f"âœ… Embedding model '{EMBEDDING_MODEL_NAME}' loaded successfully")
except ImportError as e:
    print(f"âš ï¸  sentence-transformers not available: {e}")
    print("âš ï¸  Using fallback mode.")
except Exception as e:
    print(f"âŒ Error loading embedding model: {e}")
    print("âš ï¸  Using fallback mode.")
    MODEL = None

# Distance threshold: umbral mÃ¡s estricto para evitar respuestas irrelevantes
MAX_DISTANCE_THRESHOLD = 0.65

# System prompt para generar respuestas naturales
SYSTEM_PROMPT = """
Eres un asistente virtual especializado de Mawell, una empresa de equipos y servicios industriales.

INSTRUCCIONES CRÃTICAS:
1. SOLO responde sobre temas relacionados con Mawell: equipos industriales, servicios tÃ©cnicos, productos de la empresa
2. Si la pregunta NO estÃ¡ relacionada con Mawell, responde: "Lo siento, solo puedo ayudarte con informaciÃ³n sobre los equipos y servicios de Mawell"
3. Usa ÃšNICAMENTE la informaciÃ³n proporcionada en el contexto
4. Reformula la informaciÃ³n con tus propias palabras, NUNCA copies literalmente
5. MantÃ©n un tono profesional y tÃ©cnico apropiado
6. Estructura tu respuesta de manera clara y organizada
7. SIEMPRE termina con: "Â¿Puedo ayudarte con algo mÃ¡s?"

REGLA ABSOLUTA: Si el contexto no es relevante para la pregunta sobre Mawell, NO inventes informaciÃ³n.
""".strip()


def get_relevant_chunks(query: str, top_k=4):
    try:
        # Try to use vector search if available
        if MODEL and os.path.exists(INDEX_FILE) and os.path.exists(DOC_FILE):
            try:
                import faiss
                index = faiss.read_index(INDEX_FILE)
                with open(DOC_FILE, "rb") as f:
                    docs = pickle.load(f)

                query_vec = MODEL.encode([query])
                
                # Verificar compatibilidad de dimensiones
                if query_vec.shape[1] != index.d:
                    print(f"âš ï¸  Usando bÃºsqueda por palabras clave (FAISS incompatible)")
                    raise ValueError("Dimension mismatch")
                
                distances, indices = index.search(query_vec, top_k)

                # Si ninguna distancia es suficientemente baja, no hay contexto relevante
                if all(dist > MAX_DISTANCE_THRESHOLD for dist in distances[0]):
                    return None

                return [docs[i] for i in indices[0]]
            except ImportError:
                print("âš ï¸  FAISS not available, using fallback")
        
        # Fallback: bÃºsqueda inteligente en docs de Mawell
        if os.path.exists(DOC_FILE):
            try:
                with open(DOC_FILE, "rb") as f:
                    docs = pickle.load(f)
                
                print(f"ğŸ“š Buscando en {len(docs)} fragmentos de documentos de Mawell...")
                
                # BÃºsqueda mÃ¡s inteligente por keywords relevantes
                query_lower = query.lower().strip()
                query_words = [word for word in query_lower.split() if len(word) > 2]
                
                # Mapeo de sinÃ³nimos especÃ­ficos de Mawell
                synonyms = {
                    'equipos': ['equipos', 'equipo', 'maquinaria', 'dispositivos', 'aparatos'],
                    'servicios': ['servicios', 'servicio', 'mantenimiento', 'instalaciÃ³n', 'reparaciÃ³n'],
                    'bombas': ['bomba', 'bombas', 'bomba centrÃ­fuga', 'bomba dosificadora'],
                    'filtros': ['filtro', 'filtros', 'filtraciÃ³n', 'purificaciÃ³n'],
                    'agua': ['agua', 'ultrapura', 'purificaciÃ³n', 'tratamiento'],
                    'anÃ¡lisis': ['anÃ¡lisis', 'analizador', 'termogrÃ¡fico', 'detecciÃ³n'],
                    'industrial': ['industrial', 'industria', 'tÃ©cnico', 'profesional'],
                    'mawell': ['mawell', 'empresa', 'compaÃ±Ã­a']
                }
                
                # Expandir palabras de bÃºsqueda con sinÃ³nimos
                expanded_words = set(query_words)
                for word in query_words:
                    for key, syns in synonyms.items():
                        if word in syns:
                            expanded_words.update(syns)
                
                relevant_docs = []
                for doc in docs:
                    # Manejar formato dict o string
                    doc_text = doc.get('text', str(doc)) if isinstance(doc, dict) else str(doc)
                    doc_lower = doc_text.lower()
                    score = 0
                    
                    # Verificar que el documento sea realmente sobre Mawell y no sea solo preguntas
                    mawell_indicators = ['mawell', 'equipo', 'servicio', 'industrial', 'bomba', 'filtro', 'sistema']
                    has_mawell_content = any(indicator in doc_lower for indicator in mawell_indicators)
                    
                    # Filtrar documentos que son principalmente preguntas
                    question_indicators = ['Â¿', '?']
                    question_count = sum(doc_text.count(indicator) for indicator in question_indicators)
                    total_sentences = max(doc_text.count('.') + doc_text.count('?') + doc_text.count('!'), 1)
                    question_ratio = question_count / total_sentences
                    
                    if not has_mawell_content or question_ratio > 0.7:  # Si mÃ¡s del 70% son preguntas, saltar
                        continue
                    
                    # Puntuar por coincidencias exactas de frases (mÃ¡s peso)
                    if query_lower in doc_lower:
                        score += 50
                    
                    # Puntuar por palabras clave importantes
                    important_matches = 0
                    for word in query_words:
                        if len(word) > 3 and word in doc_lower:  # Solo palabras importantes
                            count = doc_lower.count(word)
                            score += count * 10
                            important_matches += count
                    
                    # Puntuar por sinÃ³nimos expandidos (menos peso)
                    for word in expanded_words:
                        if word not in query_words:  # Solo sinÃ³nimos adicionales
                            count = doc_lower.count(word)
                            score += count * 3
                    
                    # Bonus para tÃ­tulos/encabezados con palabras clave
                    header_text = doc_text[:150].lower()
                    for word in query_words:
                        if word in header_text:
                            score += 15
                    
                    # Requerir al menos 2 coincidencias importantes o una coincidencia exacta
                    if score >= 20 and (important_matches >= 2 or query_lower in doc_lower):
                        relevant_docs.append((doc_text, score))
                
                # Ordenar por relevancia y tomar solo los mÃ¡s relevantes
                if relevant_docs:
                    relevant_docs.sort(key=lambda x: x[1], reverse=True)
                    # Filtrar solo documentos con alta puntuaciÃ³n
                    high_score_docs = [(doc, score) for doc, score in relevant_docs if score >= 30]
                    
                    if high_score_docs:
                        best_docs = [doc for doc, score in high_score_docs[:top_k]]
                        print(f"âœ… Encontrados {len(best_docs)} fragmentos altamente relevantes (scores: {[score for _, score in high_score_docs[:top_k]]})")
                        return best_docs
                
                print("âš ï¸ No se encontraron fragmentos relevantes")
                return None
            except Exception as e:
                print(f"âŒ Error leyendo documentos: {e}")
                pass
        
        print("âŒ No vector database or docs available")
        return None
        
    except Exception as e:
        # Intentar fallback simple si hay error
        try:
            if os.path.exists(DOC_FILE):
                with open(DOC_FILE, "rb") as f:
                    docs = pickle.load(f)
                print(f"ğŸ“š Usando bÃºsqueda por palabras clave con {len(docs)} documentos...")
                # Devolver algunos documentos como fallback
                return docs[:2] if len(docs) >= 2 else docs
        except Exception as fallback_error:
            print(f"âŒ Error accediendo a documentos: {fallback_error}")
        return None


def ask_mistral_with_context(query: str) -> dict:
    chunks = get_relevant_chunks(query)

    if not chunks:
        # Verificar si la pregunta estÃ¡ relacionada con Mawell
        query_lower = query.lower()
        
        # TÃ©rminos claramente irrelevantes
        irrelevant_terms = [
            'comida', 'ropa', 'clima', 'tiempo', 'cocinar', 'receta', 'capital', 'paÃ­s', 'ciudad',
            'polÃ­tica', 'deportes', 'mÃºsica', 'pelÃ­cula', 'entretenimiento',
            'salud personal', 'medicina', 'educaciÃ³n general'
        ]
        
        # Verificar si es claramente irrelevante
        is_clearly_irrelevant = any(term in query_lower for term in irrelevant_terms)
        
        if is_clearly_irrelevant:
            basic_response = (
                "Lo siento, solo puedo ayudarte con informaciÃ³n sobre los equipos y servicios de Mawell. "
                "Puedo proporcionarte informaciÃ³n sobre nuestros equipos industriales, servicios tÃ©cnicos, "
                "sistemas de filtraciÃ³n, bombas, analizadores y mÃ¡s. "
                "Â¿Puedo ayudarte con algo mÃ¡s?"
            )
        else:
            # Pregunta relacionada con Mawell pero sin contexto especÃ­fico
            basic_response = (
                "Hola, soy el asistente virtual de Mawell. "
                "No encontrÃ© informaciÃ³n especÃ­fica sobre tu consulta en los documentos disponibles. "
                "Â¿PodrÃ­as ser mÃ¡s especÃ­fico sobre quÃ© equipo o servicio de Mawell te interesa? "
                "Tengo informaciÃ³n sobre equipos industriales, servicios tÃ©cnicos y mÃ¡s. "
                "Â¿Puedo ayudarte con algo mÃ¡s?"
            )
        
        return {
            "question": query,
            "answer": basic_response
        }

    # Si hay contexto, crear respuesta basada en los documentos
    context = "\n".join(chunks)
    
    # Intentar usar Ollama con prompt mejorado
    try:
        # Crear prompt estructurado para mejor respuesta
        full_prompt = f"""
{SYSTEM_PROMPT}

CONTEXTO DE MAWELL:
{context}

PREGUNTA DEL USUARIO: {query}

INSTRUCCIÃ“N: BasÃ¡ndote en el contexto proporcionado, responde la pregunta del usuario de manera natural y conversacional. Reformula la informaciÃ³n con tus propias palabras, no copies literalmente el texto del contexto.

RESPUESTA:"""

        response = requests.post(
            OLLAMA_API_URL, 
            json={
                "model": OLLAMA_MODEL_NAME,
                "prompt": full_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "max_tokens": 500
                }
            },
            timeout=100 # Timeout un poco mÃ¡s largo para respuestas elaboradas
        )

        if response.status_code == 200:
            answer = response.json().get("response", "").strip()
            # Validar que la respuesta no sea solo el contexto copiado
            if len(answer) > 50 and not _is_mostly_copied_text(answer, context):
                return {
                    "question": query,
                    "answer": answer
                }
        else:
            raise Exception(f"Ollama error: {response.status_code}")
            
    except Exception as e:
        print(f"âš ï¸ Ollama no disponible, usando generador de respuestas inteligente: {e}")
    
    # Fallback: generador de respuestas inteligente sin IA externa
    answer = _generate_intelligent_response(query, context)
    
    return {
        "question": query,
        "answer": answer
    }


def _is_mostly_copied_text(response: str, context: str, threshold: float = 0.8) -> bool:
    """Detecta si la respuesta es principalmente texto copiado del contexto"""
    if not response or not context:
        return False
    
    response_words = set(response.lower().split())
    context_words = set(context.lower().split())
    
    if len(response_words) == 0:
        return True
    
    overlap = len(response_words.intersection(context_words))
    similarity = overlap / len(response_words)
    
    return similarity > threshold


def _generate_intelligent_response(query: str, context: str) -> str:
    """
    Genera una respuesta inteligente basada en el contexto sin usar IA externa.
    Reformula y estructura la informaciÃ³n de manera natural.
    """
    # Limpiar y preparar el contexto, filtrando preguntas
    context_lines = []
    for line in context.split('\n'):
        line_clean = line.strip()
        if (len(line_clean) > 20 and 
            not line_clean.startswith('Â¿') and 
            not line_clean.endswith('?') and
            not 'cÃ³mo puedo' in line_clean.lower() and
            not 'cuÃ¡nto cuesta' in line_clean.lower() and
            not 'dÃ³nde estÃ¡n' in line_clean.lower() and
            not 'quÃ© pasos' in line_clean.lower()):
            context_lines.append(line_clean)
    
    # Crear respuesta basada en el contexto disponible
    query_lower = query.lower()
    
    if context_lines:
        # Usar el contexto real cuando estÃ© disponible
        response = "BasÃ¡ndome en la informaciÃ³n de Mawell:\n\n"
        response += context_lines[0]
        if len(context_lines) > 1:
            response += f" {context_lines[1]}"
        response += "\n\nÂ¿Puedo ayudarte con algo mÃ¡s?"
        return response
    else:
        # Fallback para casos especÃ­ficos cuando no hay contexto
        if 'misiÃ³n' in query_lower:
            return "La misiÃ³n de Mawell es alcanzar la satisfacciÃ³n de sus clientes ofreciendo servicios y productos de alta calidad.\n\nÂ¿Puedo ayudarte con algo mÃ¡s?"
        elif 'visiÃ³n' in query_lower:
            return "La visiÃ³n de Mawell es ser parte de la soluciÃ³n a problemas medioambientales, trabajando en armonÃ­a con clientes y aliados estratÃ©gicos.\n\nÂ¿Puedo ayudarte con algo mÃ¡s?"
        else:
            return "He encontrado informaciÃ³n relevante sobre tu consulta en nuestros documentos de Mawell.\n\nÂ¿Puedo ayudarte con algo mÃ¡s?"


def _create_simple_response(query: str) -> str:
    """Crea respuesta simple cuando no hay contexto Ãºtil"""
    return ("Lo siento, no encontrÃ© informaciÃ³n especÃ­fica sobre tu consulta. "
            "Â¿PodrÃ­as ser mÃ¡s especÃ­fico sobre quÃ© equipo o servicio de Mawell te interesa? "
            "Â¿Puedo ayudarte con algo mÃ¡s?")


